---
layout: default
title: Follow me on LinkedIn
description: LinkedIn
keywords: ml, ai, tensorflow
url: https://www.linkedin.com/in/lemmonw/
custom_css: index.css
custom_js: index.js
---

<div class="section grey">
    
    <div class="Grid container">
        <div id="philosophy-text" class="Grid-cell u-size4of6 u-before1of6 u-after1of6">
            <h1 class="small-title center-text mega-margin">
                <a href="https://colab.research.google.com/drive/1sO0f4rlwj_QOUHVgpTDe6Gs5HIrNCDQM" target="_blank">From LSTMs to Attention for Time Series Forecasting. (in progress)</a>
            </h1>
            <p class="center-text mega-margin">What gains do attention mechanisms provide over LSTMs for time series forecasting?</p>
        </div>
    </div>
    
    <div class="Grid container">
        <div id="philosophy-text" class="Grid-cell u-size4of6 u-before1of6 u-after1of6">
            <h1 class="small-title center-text mega-margin">
                <a href="https://colab.research.google.com/drive/1mMzTH7cBYhtl166h5hgp7R3d0-820PaK" target="_blank">Predicting Predictability (in progress)</a>
            </h1>
            <p class="center-text mega-margin">Deep learning often pushes Bayesian methods aside, but how can we bring them together to measure a model conficence? Is it simpler to measure a model's confidence after-the-fact, or can we build-into or extract this information from the model itself? How well does a simpler I-dont-know approach compare?</p>
        </div>
    </div>
    
    <div class="Grid container">
        <div id="philosophy-text" class="Grid-cell u-size4of6 u-before1of6 u-after1of6">
            <h1 class="small-title center-text mega-margin">
                <a href="https://colab.research.google.com/drive/1LnyByEmD-rgwhmv_KSt497fw3yyBFGUp" target="_blank">Time Series Forecasting, data preprocessing, models, and Baselines  (in progress</a>
            </h1>
            <p class="center-text mega-margin">I ask the questions, "How does input preprocessing affect model performance?," "What feature engineering can help learning?," and "What basic network architectures are sufficient for learning?"</p>
        </div>
    </div>
    
    <div class="Grid container">
        <div id="philosophy-text" class="Grid-cell u-size4of6 u-before1of6 u-after1of6">
            <h1 class="small-title center-text mega-margin">
                <a href="https://colab.research.google.com/drive/12E7wJFLnv3HvaqT6bGtNyQVH5wgH56op" target="_blank">Hurst Implementation Comparison</a>
            </h1>
            <p class="center-text mega-margin">Several Implementations of the Hurst Coefficient initially contracticted eachother in output. I wanted to see how they compared, and try to understand why some fail. Also, I am interested in the change of coefficient as timescale is reduced and time series are subsequently broken down in to smaller chunks. An interesting take would be to perform candlestick summarizations and compute hurst coefficients over the summaries to see how the coefficient evolves as summarizations are performed.</p>
        </div>
    </div>
    
    
    
    <div class="Grid container">
        <div id="philosophy-text" class="Grid-cell u-size4of6 u-before1of6 u-after1of6">
            <h1 class="small-title center-text mega-margin">
                <a href="https://github.com/wlemmon/gt-CS7637-Knowledge-Based-AI-Cognitive-Systems" target="_blank">Knowledge Based AI</a>
            </h1>
            <p class="center-text mega-margin">Taught by Ashok Goel and David Joyner, this repo houses my work from class. My implementation was in the top 3 for solving Ravin's Matrices on a held-out test set, and we published the results were published in ICCC (June 2015, pp. 23-30). The repo is private to discourage plagairism.</p>
        </div>
    </div>
    
    <div class="Grid container">
        <div id="philosophy-text" class="Grid-cell u-size4of6 u-before1of6 u-after1of6">
            <h1 class="small-title center-text mega-margin">
                <a href="https://medium.com/@lemmon.warren/funnelsort-ef45c003b2d1" target="_blank">Debriefing for FunnelSort implementation</a>
            </h1>
            <p class="center-text mega-margin">FunnelSort is a cache-oblivious sorting algorithm. The main idea is to access memory contiguously by laying out accesses recursively in a fractal pattern. A recursive k-funnel is very similar in concept to a space filling curve.</p>
        </div>
    </div>
</div>
